'''

Text generation involves generating text using machine learning techniques. The 
purpose of text generation is to automatically generate text that is indistinguishable 
from a text written by a human.



## What is GPT-2 Model?

GPT-2 stands for Generative Pre-trained Transformer 2. It is an open-source 
Natural Language Processing model created by OpenAI. It can generate 
paragraphs of text with state of the art performance on many language 
benchmarks. It is also used for machine translation, question answering, and text 
summarization.

To use the GPT-2 model to generate text using Python, we need to install the 
Transformers library in Python. It can be easily installed using the pip command on 
your command prompt or terminal as mentioned below:

    pip install transformers

I hope you now have understood what GPT-2 model is and how you can install it in 
your Python virtual environment. You can read more about this model here.
[https://openai.com/index/better-language-models/]

'''

from transformers import pipeline

'''
This line imports the pipeline function from the transformers library. The pipeline function 
is a high-level API provided by the transformers library to easily access various natural 
language processing tasks like text generation, sentiment analysis, translation, etc.
'''

model = pipeline("text-generation", model = "gpt2")

'''
Here, the pipeline function is used to create a text generation pipeline. The "text-generation" 
argument specifies that you want to generate text, and the model="gpt2" argument indicates that 
we want to use the GPT-2 model. GPT-2 is a powerful language model developed by OpenAI that can 
generate coherent and contextually relevant text based on a given input.
'''

# Here’s how we can generate text using Python by using the GPT-2 model:


'''
This block of code generates text based on the input prompt "Hi, my name is Roman Reings 
'The Tribal Chief'". Let’s break down the parameters:

- Input Prompt: "Hi, my name is Roman Reings 'The Tribal Chief'" is the initial text provided 
to the model. GPT-2 will generate text that follows this input.

- do_sample=True: This indicates that the model should sample from the probability distribution of 
words rather than always choosing the word with the highest probability. This allows for more 
diverse and creative text generation.

- top_k=50: This parameter limits the sampling pool to the top 50 most likely next words. 
It helps in reducing less probable choices, making the text more coherent while still 
allowing some creativity.

- temperature=0.9: The temperature controls the randomness of the predictions. A lower 
value (closer to 0) makes the model more conservative, while a higher value (closer to 1) 
makes it more creative. Here, 0.9 is slightly creative but not too random.

- max_length=200: This sets the maximum number of tokens (words or punctuation marks) in the 
generated text. The text generated by the model will not exceed 200 tokens.

- num_return_sentences=3: This tells the model to generate three different sentences (or continuations) 
based on the input prompt. You’ll get three variations of text starting with the input sentence.
'''

sentence = model("Hi, my name is Roman Reings 'The Tribal Chief'",
                 do_sample = True, top_k = 50,
                 temperature = 0.9, max_length = 200,
                 num_return_sentences = 3)

for i in sentence:
    print(i["generated_text"])

'''
This loop iterates over the three generated sentences (stored in sentence). 
Each i in the loop is a dictionary with a key "generated_text" containing 
the generated text. The loop prints out each of these texts.
'''    
    
    
    
    
    
    

